{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6004344,"sourceType":"datasetVersion","datasetId":3438844}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets evaluate rouge_score accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:26:44.609405Z","iopub.execute_input":"2025-12-14T15:26:44.610006Z","iopub.status.idle":"2025-12-14T15:26:48.092568Z","shell.execute_reply.started":"2025-12-14T15:26:44.609971Z","shell.execute_reply":"2025-12-14T15:26:48.091571Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install protobuf==3.20.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:26:51.212280Z","iopub.execute_input":"2025-12-14T15:26:51.212497Z","iopub.status.idle":"2025-12-14T15:26:54.307702Z","shell.execute_reply.started":"2025-12-14T15:26:51.212474Z","shell.execute_reply":"2025-12-14T15:26:54.306994Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.11/dist-packages (3.20.3)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer\n\nimport os\nprint(os.listdir(\"/kaggle/input/samsum-dataset-text-summarization\")) \n\ndf_train = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv\")\ndf_val = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv\")\n\ntrain_dataset = Dataset.from_pandas(df_train)\nval_dataset = Dataset.from_pandas(df_val)\ntest_dataset = Dataset.from_pandas(df_test)\n\ndataset = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})\n\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:27:20.194069Z","iopub.execute_input":"2025-12-14T15:27:20.194399Z","iopub.status.idle":"2025-12-14T15:27:25.768242Z","shell.execute_reply.started":"2025-12-14T15:27:20.194363Z","shell.execute_reply":"2025-12-14T15:27:25.767330Z"}},"outputs":[{"name":"stdout","text":"['samsum-train.csv', 'samsum_dataset', 'samsum-test.csv', 'samsum-validation.csv']\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 14732\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 818\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 819\n    })\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"model_checkpoint = \"t5-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\nprefix = \"summarize: \"\n\ndef preprocess_function(examples):\n    inputs = [prefix + str(doc or \"\") for doc in examples[\"dialogue\"]]\n    \n    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer([str(s or \"\") for s in examples[\"summary\"]], max_length=128, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_datasets = dataset.map(preprocess_function, batched=True)\nprint(\"Preprocessing successful!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:28:39.315681Z","iopub.execute_input":"2025-12-14T15:28:39.316293Z","iopub.status.idle":"2025-12-14T15:28:44.560367Z","shell.execute_reply.started":"2025-12-14T15:28:39.316261Z","shell.execute_reply":"2025-12-14T15:28:44.559567Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf6379e45f1247a4a2a5909b35d2e41e"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49efa79af5bc4a738a2aa1ca96be79f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51b3e19f7995408b9d42f18d730bae7e"}},"metadata":{}},{"name":"stdout","text":"Preprocessing successful!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nimport evaluate\nimport numpy as np\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\nrouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./hoshiBmaTchi_model\",\n    eval_strategy=\"epoch\",            \n    learning_rate=2e-5,\n    per_device_train_batch_size=4,   \n    per_device_eval_batch_size=4,    \n    gradient_accumulation_steps=2,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=3,\n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:29:11.332447Z","iopub.execute_input":"2025-12-14T15:29:11.333008Z","iopub.status.idle":"2025-12-14T16:31:08.804727Z","shell.execute_reply.started":"2025-12-14T15:29:11.332982Z","shell.execute_reply":"2025-12-14T16:31:08.804065Z"}},"outputs":[{"name":"stderr","text":"2025-12-14 15:29:11.612843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765726151.630589     229 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765726151.635859     229 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/tmp/ipykernel_229/1177684168.py:44: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2763' max='2763' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2763/2763 1:01:46, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.758000</td>\n      <td>1.466857</td>\n      <td>0.463100</td>\n      <td>0.222800</td>\n      <td>0.387400</td>\n      <td>0.387300</td>\n      <td>17.223700</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.569700</td>\n      <td>1.430724</td>\n      <td>0.470300</td>\n      <td>0.231700</td>\n      <td>0.395100</td>\n      <td>0.395500</td>\n      <td>17.343500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.524100</td>\n      <td>1.422379</td>\n      <td>0.471600</td>\n      <td>0.232700</td>\n      <td>0.396900</td>\n      <td>0.397300</td>\n      <td>17.379000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2763, training_loss=1.597115040688337, metrics={'train_runtime': 3708.9184, 'train_samples_per_second': 11.916, 'train_steps_per_second': 0.745, 'total_flos': 1.732187380174848e+16, 'train_loss': 1.597115040688337, 'epoch': 3.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"eval_results = trainer.evaluate()\n\nprint(f\"ROUGE-1: {eval_results['eval_rouge1']:.4f}\")\nprint(f\"ROUGE-2: {eval_results['eval_rouge2']:.4f}\")\nprint(f\"ROUGE-L: {eval_results['eval_rougeL']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:39:08.826242Z","iopub.execute_input":"2025-12-14T16:39:08.826561Z","iopub.status.idle":"2025-12-14T16:40:34.721959Z","shell.execute_reply.started":"2025-12-14T16:39:08.826539Z","shell.execute_reply":"2025-12-14T16:40:34.721056Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [103/103 01:23]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"ROUGE-1: 0.4716\nROUGE-2: 0.2327\nROUGE-L: 0.3969\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\nmodel_to_test = trainer.model\ntokenizer_to_test = tokenizer\n\nsample_text = \"\"\"\nomg guys you won't believe what happened today at the cafe. \nI was ordering my usual iced latte and the barista totally spilled it all over the counter. \nI felt so bad for him, he looked so stressed! But then the manager came out and gave me a free croissant \nto say sorry. It was actually the best croissant I've ever had. \nTotally made my day better after that rough start!\n\"\"\"\n\ninput_text = \"summarize: \" + sample_text\ninputs = tokenizer_to_test(input_text, return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model_to_test.generate(inputs[\"input_ids\"], max_new_tokens=50, num_beams=4, early_stopping=True)\nsummary = tokenizer_to_test.decode(outputs[0], skip_special_tokens=True)\n\nprint(\"Original Caption:\")\nprint(sample_text)\nprint(\"-\" * 30)\nprint(\"BapTion Summary:\")\nprint(summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:40:57.582043Z","iopub.execute_input":"2025-12-14T16:40:57.582650Z","iopub.status.idle":"2025-12-14T16:40:58.177184Z","shell.execute_reply.started":"2025-12-14T16:40:57.582623Z","shell.execute_reply":"2025-12-14T16:40:58.176420Z"}},"outputs":[{"name":"stdout","text":"Original Caption:\n\nomg guys you won't believe what happened today at the cafe. \nI was ordering my usual iced latte and the barista totally spilled it all over the counter. \nI felt so bad for him, he looked so stressed! But then the manager came out and gave me a free croissant \nto say sorry. It was actually the best croissant I've ever had. \nTotally made my day better after that rough start!\n\n------------------------------\nBapTion Summary:\nThe barista spilled her iced latte all over the counter. The manager gave her a free croissant.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import shutil\n\noutput_path = \"./baption_final_model\"\ntrainer.save_model(output_path)\ntokenizer.save_pretrained(output_path)\n\nshutil.make_archive(\"baption_model\", 'zip', output_path)\n\nprint(\"Success! Go to the 'Output' section of Kaggle (right sidebar) and download 'baption_model.zip'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:43:20.756671Z","iopub.execute_input":"2025-12-14T16:43:20.757270Z","iopub.status.idle":"2025-12-14T16:44:07.767246Z","shell.execute_reply.started":"2025-12-14T16:43:20.757246Z","shell.execute_reply":"2025-12-14T16:44:07.766441Z"}},"outputs":[{"name":"stdout","text":"✅ Success! Go to the 'Output' section of Kaggle (right sidebar) and download 'baption_model.zip'.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(r'baption_model.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:44:22.230093Z","iopub.execute_input":"2025-12-14T16:44:22.230650Z","iopub.status.idle":"2025-12-14T16:44:22.235297Z","shell.execute_reply.started":"2025-12-14T16:44:22.230620Z","shell.execute_reply":"2025-12-14T16:44:22.234633Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/baption_model.zip","text/html":"<a href='baption_model.zip' target='_blank'>baption_model.zip</a><br>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:59:22.839113Z","iopub.execute_input":"2025-12-14T16:59:22.839451Z","iopub.status.idle":"2025-12-14T16:59:22.854344Z","shell.execute_reply.started":"2025-12-14T16:59:22.839428Z","shell.execute_reply":"2025-12-14T16:59:22.853529Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1ad60bea4f740788d4c8eab65f5790a"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"repo_name = \"Maungvee/baption-summarizer\" \n\ntrainer.push_to_hub(repo_name)\ntokenizer.push_to_hub(repo_name)\n\nprint(f\"Model uploaded to: https://huggingface.co/{repo_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:59:27.759737Z","iopub.execute_input":"2025-12-14T16:59:27.760012Z","iopub.status.idle":"2025-12-14T16:59:46.078971Z","shell.execute_reply.started":"2025-12-14T16:59:27.759990Z","shell.execute_reply":"2025-12-14T16:59:46.078238Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15707b36809e4a6ca92b112b3470a81c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c73b0af557d4c9ba6e1604cf12a8df6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc68c2b81f6546cba102830e20c11cc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fecf2fd2cd945f8a868aa57ebd158aa"}},"metadata":{}},{"name":"stdout","text":"Model uploaded to: https://huggingface.co/Maungvee/baption-summarizer\n","output_type":"stream"}],"execution_count":20}]}